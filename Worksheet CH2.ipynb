{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a104e70c",
   "metadata": {},
   "source": [
    "**Worksheet_1: End-to-end Machine Learning project**<br/>\n",
    "In this worksheet we will work with an Automobile Data Set to try and predict the price of a car based on a bunch of features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb88922",
   "metadata": {},
   "source": [
    "## Look at Big Picture:\n",
    "it is always good to know what is the goal of the project you are working on so you can better make dessitions about the type of output you are looking for(i.e. regression, classification), and what methods you should use(i.e.supervised, unsupervised, RL).<br/>\n",
    "In this case the goal of this Project is to predict the numerical value of a diamond given some atributes, lets look at the data set and see what we are dealing with"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1051cea4",
   "metadata": {},
   "source": [
    "## Get the Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c938ec39",
   "metadata": {},
   "source": [
    "### Attribute Information:\n",
    "price price in US dollars (\\$326 — \\$18,823)\n",
    "\n",
    "carat weight of the diamond (0.2–5.01)\n",
    "\n",
    "cut quality of the cut (Fair, Good, Very Good, Premium, Ideal)\n",
    "\n",
    "color diamond colour, from J (worst) to D (best)\n",
    "\n",
    "clarity a measurement of how clear the diamond is (I1 (worst), SI2, SI1, VS2, VS1, VVS2, VVS1, IF (best))\n",
    "\n",
    "x length in mm (0–10.74)\n",
    "\n",
    "y width in mm (0–58.9)\n",
    "\n",
    "z depth in mm (0–31.8)\n",
    "\n",
    "depth total depth percentage = z / mean(x, y) = 2 * z / (x + y) (43–79)\n",
    "\n",
    "table width of top of diamond relative to widest point (43–95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e5f1233",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ba2ba03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d0007da",
   "metadata": {},
   "outputs": [],
   "source": [
    "diamond=sns.load_dataset('diamonds', cache=True, data_home=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2639a652",
   "metadata": {},
   "source": [
    "Problem 1.1: Take a quick look at the data\n",
    "- take a look at the first few lines of the data\n",
    "- check if any data is missing/ the data types\n",
    "- check the min max mean std of the numerical data\n",
    "- make histagram of all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc78f63a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d003c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fc4630",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae1f6ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76ff02f6",
   "metadata": {},
   "source": [
    "## Make test set\n",
    "we make a test set so we dont over fit the model, meaning if we had no test set the model would do very well on the data it was trained on but it would do a lot worse if given an out of sample exaple."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a922f33",
   "metadata": {},
   "source": [
    "problem 2: split data into test set and training set (there is more then one way to do this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efd50fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "093e1e6c",
   "metadata": {},
   "source": [
    "## Discover and Visualize the Data to Gain Insights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81246c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "diamond = train_set.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7bbed846",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26546</th>\n",
       "      <td>2.01</td>\n",
       "      <td>Good</td>\n",
       "      <td>F</td>\n",
       "      <td>SI2</td>\n",
       "      <td>58.1</td>\n",
       "      <td>64.0</td>\n",
       "      <td>16231</td>\n",
       "      <td>8.23</td>\n",
       "      <td>8.19</td>\n",
       "      <td>4.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9159</th>\n",
       "      <td>1.01</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>4540</td>\n",
       "      <td>6.57</td>\n",
       "      <td>6.49</td>\n",
       "      <td>3.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14131</th>\n",
       "      <td>1.10</td>\n",
       "      <td>Premium</td>\n",
       "      <td>H</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.5</td>\n",
       "      <td>58.0</td>\n",
       "      <td>5729</td>\n",
       "      <td>6.59</td>\n",
       "      <td>6.54</td>\n",
       "      <td>4.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15757</th>\n",
       "      <td>1.50</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>65.0</td>\n",
       "      <td>6300</td>\n",
       "      <td>7.21</td>\n",
       "      <td>7.17</td>\n",
       "      <td>4.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24632</th>\n",
       "      <td>1.52</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>G</td>\n",
       "      <td>VS1</td>\n",
       "      <td>62.1</td>\n",
       "      <td>57.0</td>\n",
       "      <td>12968</td>\n",
       "      <td>7.27</td>\n",
       "      <td>7.32</td>\n",
       "      <td>4.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11284</th>\n",
       "      <td>1.05</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>I</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>59.0</td>\n",
       "      <td>4975</td>\n",
       "      <td>6.48</td>\n",
       "      <td>6.51</td>\n",
       "      <td>4.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44732</th>\n",
       "      <td>0.47</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>D</td>\n",
       "      <td>VS1</td>\n",
       "      <td>61.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1617</td>\n",
       "      <td>5.03</td>\n",
       "      <td>5.01</td>\n",
       "      <td>3.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38158</th>\n",
       "      <td>0.33</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>F</td>\n",
       "      <td>IF</td>\n",
       "      <td>60.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1014</td>\n",
       "      <td>4.49</td>\n",
       "      <td>4.46</td>\n",
       "      <td>2.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0.90</td>\n",
       "      <td>Premium</td>\n",
       "      <td>J</td>\n",
       "      <td>SI1</td>\n",
       "      <td>62.8</td>\n",
       "      <td>59.0</td>\n",
       "      <td>2871</td>\n",
       "      <td>6.13</td>\n",
       "      <td>6.03</td>\n",
       "      <td>3.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>1.14</td>\n",
       "      <td>Premium</td>\n",
       "      <td>F</td>\n",
       "      <td>SI1</td>\n",
       "      <td>60.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>6320</td>\n",
       "      <td>6.82</td>\n",
       "      <td>6.79</td>\n",
       "      <td>4.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43152 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       carat        cut color clarity  depth  table  price     x     y     z\n",
       "26546   2.01       Good     F     SI2   58.1   64.0  16231  8.23  8.19  4.77\n",
       "9159    1.01  Very Good     E     SI2   60.0   60.0   4540  6.57  6.49  3.92\n",
       "14131   1.10    Premium     H     VS2   62.5   58.0   5729  6.59  6.54  4.10\n",
       "15757   1.50       Good     E     SI2   61.5   65.0   6300  7.21  7.17  4.42\n",
       "24632   1.52  Very Good     G     VS1   62.1   57.0  12968  7.27  7.32  4.53\n",
       "...      ...        ...   ...     ...    ...    ...    ...   ...   ...   ...\n",
       "11284   1.05  Very Good     I     VS2   62.4   59.0   4975  6.48  6.51  4.05\n",
       "44732   0.47      Ideal     D     VS1   61.0   55.0   1617  5.03  5.01  3.06\n",
       "38158   0.33  Very Good     F      IF   60.3   58.0   1014  4.49  4.46  2.70\n",
       "860     0.90    Premium     J     SI1   62.8   59.0   2871  6.13  6.03  3.82\n",
       "15795   1.14    Premium     F     SI1   60.4   58.0   6320  6.82  6.79  4.11\n",
       "\n",
       "[43152 rows x 10 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diamond"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef07c7a",
   "metadata": {},
   "source": [
    "Problem 3: make some graphs to learn more about the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cecde30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780e7279",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d9c2002",
   "metadata": {},
   "source": [
    "problem 4: what are the most and least correlated features to price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a8225e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42518418",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5e42c26",
   "metadata": {},
   "source": [
    "### Test out diffent Attribute combinations\n",
    "after looking at the data try and make some of your own features by combining the features given to you in the data set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fe50dc",
   "metadata": {},
   "source": [
    "problem 5: try and come up with your own features and check its correlation compaired to price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478e7f08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c757b2f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955a548a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c542f36",
   "metadata": {},
   "source": [
    "## Prepare the Data for Machine Learning Algorithms\n",
    "- its best to build a transformer pipeline so we could use it in training and in testing/production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c65ea3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first lets go back to the old data\n",
    "diamond = train_set.drop('price', axis=1)\n",
    "diamond_price = train_set['price'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f700fa",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "most data sets are missing features so we will have to make functions to deal with this\n",
    "1. drop the entire column\n",
    "2. replace missing values with mean or zero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f484bede",
   "metadata": {},
   "source": [
    "Problem 6: use sklearns Simple Imputer to replace missing values with median value for numerical features\n",
    "\n",
    "Hint: https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e3959a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a730be7d",
   "metadata": {},
   "source": [
    "### Text and Categorical Attributes\n",
    "ML models can not take in text data so there are a few way we can convert the text data to numbers\n",
    "1. just make each category a number (i.e. cat = 1 shoe = 2)\n",
    "    - the issue with this is that shoe means it is twice cat and that just makes no sense \n",
    "2. one hot encoder: make one attribute equal to 1 and the rest 0\n",
    "3. embedding: embeds text as an array of values that has meaning to it(will learn about in later chapter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52893b7a",
   "metadata": {},
   "source": [
    "**Problem 7**: make one hot encoding for all categorical features<br/>\n",
    "Hint: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1741a3b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ac8af01",
   "metadata": {},
   "source": [
    "### Feature Scaling\n",
    "many ML algos dont work so well if the scales of the input very different so it is common to scale features before training, two methods for that are\n",
    "1. min max scaling\n",
    "2. standardization\n",
    "    - unlike min max scaling standardization does not bound values, and standardization is much less affected by outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7167e5",
   "metadata": {},
   "source": [
    "### Transformation Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf444a03",
   "metadata": {},
   "source": [
    "**Problem 8:** create a sklearn pipeline to deal with numerical missing values, and scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c6a065",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1402ebb3",
   "metadata": {},
   "source": [
    "**Problem 9:** make a pipeline that deals with num data and that converts categorical data to one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f11b0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80357ce1",
   "metadata": {},
   "source": [
    "## Select and Train a Model\n",
    "in this section we will go over how to decide if a model is good "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310ea1f3",
   "metadata": {},
   "source": [
    "### Train models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a348f21a",
   "metadata": {},
   "source": [
    "**Problem 10:** train a linear model and check how it does on the training set (get the MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c26d25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8017d583",
   "metadata": {},
   "source": [
    "**Problem 11:** train a decision tree and get the MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870b72ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "acd03a15",
   "metadata": {},
   "source": [
    "### Cross validation\n",
    "A better way to evaluate a model is using cross validation, cross validation basicly splits your training data into n parts (i.e. 5) and trains on 4 of them then tests on the fifth,  then takes the next 4 and does the same.<br/>\n",
    "\n",
    "here is an example of how to do it with Sklearn, wont actually run bc fake variables \n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "    scores = cross_val_score(Model, X_data, Y_data,\n",
    "                             scoring=\"neg_mean_squared_error\", cv=10)\n",
    "    tree_rmse_scores = np.sqrt(-scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4fb46743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(random_state=42)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "forest_reg.fit(diamond_prepared, train_set['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895c3d19",
   "metadata": {},
   "source": [
    "**Problem 12:** use cross validation to evaluate your DecisionTreeRegressor, LinearRegression, and RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd80904",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a3f621",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a4dba1f",
   "metadata": {},
   "source": [
    "## Fine Tune Model\n",
    "now that we have some good models we will try and fine to the best one (random forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc9b5fc",
   "metadata": {},
   "source": [
    "### Grid Search\n",
    "Grid search is a method for looking for the best hyper peramiter by trying every combination \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fd6fb68e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeRegressor(),\n",
       "             param_grid=[{'max_depth': [3, 10, 30],\n",
       "                          'max_leaf_nodes': [5, 10, 35],\n",
       "                          'min_samples_leaf': [1, 2, 4]}],\n",
       "             return_train_score=True, scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    # try 12 (3×4) combinations of hyperparameters\n",
    "    {'max_depth': [3, 10, 30], 'min_samples_leaf': [1, 2, 4],'max_leaf_nodes':[5,10,35]}\n",
    "  ]\n",
    "\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "# train across 5 folds, that's a total of (12+6)*5=90 rounds of training \n",
    "grid_search = GridSearchCV(tree_reg, param_grid, cv=5,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           return_train_score=True)\n",
    "grid_search.fit(diamond_prepared, train_set['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "23137fb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 30, 'max_leaf_nodes': 35, 'min_samples_leaf': 1}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f45677",
   "metadata": {},
   "source": [
    "### Random Search\n",
    "in many casses it may take too long to look through all possible peramiters so random search just searches through some random combinations of peramitors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cd3f63ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=DecisionTreeRegressor(),\n",
       "                   param_distributions={'max_depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fe803ffc910>,\n",
       "                                        'max_leaf_nodes': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fe803fea7f0>,\n",
       "                                        'min_samples_leaf': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fe8074ae250>},\n",
       "                   random_state=42, scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_distribs = {\n",
    "        'max_depth': randint(low=1, high=200),\n",
    "        'min_samples_leaf': randint(low=1, high=8),\n",
    "        'max_leaf_nodes':randint(low=5, high=20)\n",
    "    }\n",
    "\n",
    "tree_reg = DecisionTreeRegressor()\n",
    "rnd_search = RandomizedSearchCV(tree_reg, param_distributions=param_distribs,\n",
    "                                n_iter=10, cv=5, scoring='neg_mean_squared_error', random_state=42)\n",
    "rnd_search.fit(diamond_prepared, train_set['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "43f5f1ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 88, 'max_leaf_nodes': 16, 'min_samples_leaf': 6}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c8a6a9",
   "metadata": {},
   "source": [
    "**Problem 13:** use grid search or random search to find the best peramitors for random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fc26fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "efee5e52",
   "metadata": {},
   "source": [
    "## Feature importance\n",
    "using the random forest model we just trained we could get the top features that the model used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "598217db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.66784703, 0.        , 0.        , 0.        , 0.26376846,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.00402215, 0.00602516, 0.0157545 , 0.        ,\n",
       "       0.01112576, 0.01915639, 0.00560907, 0.00669148, 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = rnd_search.best_estimator_.feature_importances_\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "453b6803",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.667847032533508, 'carat'),\n",
       " (0.2637684606496026, 'y'),\n",
       " (0.0, 'z'),\n",
       " (0.0, 'x'),\n",
       " (0.0, 'table'),\n",
       " (0.0, 'depth'),\n",
       " (0.0, 'Very Good'),\n",
       " (0.0, 'Premium'),\n",
       " (0.0, 'Ideal'),\n",
       " (0.0, 'Good'),\n",
       " (0.0, 'Fair')]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BUG only shows some of the results\n",
    "cat_encoder = full_pipeline.named_transformers_[\"cat\"]\n",
    "cat_one_hot_attribs = list(cat_encoder.categories_[0])\n",
    "attributes = num_attribs + cat_one_hot_attribs\n",
    "sorted(zip(feature_importances, attributes), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e69c74d",
   "metadata": {},
   "source": [
    "after this analysis we can see that carat and 'y' are the most usefull features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f3aae7",
   "metadata": {},
   "source": [
    "## Evaluate your System on the Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfdbe29",
   "metadata": {},
   "source": [
    "**Problem 14:** test results on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3662a74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
